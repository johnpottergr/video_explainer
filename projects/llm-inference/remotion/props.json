{
  "storyboard": {
    "$schema": "../../../storyboards/schema/storyboard.schema.json",
    "id": "llm_inference_complete",
    "title": "LLM Inference: How KV Caching Makes AI Fast",
    "description": "Complete explainer video covering the two phases of LLM inference and KV cache optimization",
    "duration_seconds": 165,
    "style": {
      "background_color": "#0f0f1a",
      "primary_color": "#00d9ff",
      "secondary_color": "#ff6b35",
      "accent_color": "#00ff88",
      "font_family": "Inter"
    },
    "beats": [
      {
        "id": "scene1_hook",
        "start_seconds": 0,
        "end_seconds": 17.2,
        "voiceover": "Every time you chat with an AI, something remarkable happens. A neural network generates your response, one word at a time. The naive approach? Forty tokens per second. The best systems? Over three thousand. That's eighty-seven times faster. Here's how they do it.",
        "audio_file": "scene1_hook.mp3",
        "elements": [
          {
            "id": "title",
            "component": "title_card",
            "props": {
              "title": "LLM Inference",
              "subtitle": "The Speed Problem"
            },
            "position": {
              "x": "center",
              "y": 300
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5
            },
            "exit": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 4
            }
          },
          {
            "id": "speed_comparison",
            "component": "text_reveal",
            "props": {
              "text": "40 tokens/sec \u2192 3,000+ tokens/sec",
              "fontSize": 48
            },
            "position": {
              "x": "center",
              "y": 500
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 8
            }
          },
          {
            "id": "speedup",
            "component": "text_reveal",
            "props": {
              "text": "87x faster",
              "fontSize": 72,
              "color": "#00ff88"
            },
            "position": {
              "x": "center",
              "y": 650
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 12
            }
          }
        ]
      },
      {
        "id": "scene2_phases",
        "start_seconds": 17.2,
        "end_seconds": 38.4,
        "voiceover": "LLM inference has two distinct phases. First, the prefill phase processes your entire prompt in parallel. The GPU loves this - it can crunch all tokens at once. Then comes the decode phase, generating one token at a time. Each new token depends on the previous one. This is where the bottleneck hides.",
        "audio_file": "scene2_phases.mp3",
        "elements": [
          {
            "id": "phase_title",
            "component": "title_card",
            "props": {
              "title": "Two Phases",
              "subtitle": "Prefill & Decode"
            },
            "position": {
              "x": "center",
              "y": 200
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5
            },
            "exit": {
              "type": "fade",
              "duration_seconds": 0.3,
              "delay_seconds": 3
            }
          },
          {
            "id": "prefill_tokens",
            "component": "token_row",
            "props": {
              "tokens": [
                "Explain",
                "quantum",
                "computing",
                "in",
                "simple",
                "terms"
              ],
              "mode": "prefill",
              "label": "PREFILL"
            },
            "position": {
              "x": 480,
              "y": 400
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 3
            },
            "animations": [
              {
                "action": "activate_all",
                "at_seconds": 6,
                "duration_seconds": 0.5
              }
            ]
          },
          {
            "id": "gpu_prefill",
            "component": "gpu_gauge",
            "props": {
              "utilization": 95,
              "status": "compute",
              "label": "GPU: Compute-bound"
            },
            "position": {
              "x": 480,
              "y": 600
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 5
            },
            "animations": [
              {
                "action": "fill",
                "at_seconds": 6,
                "duration_seconds": 1
              }
            ]
          },
          {
            "id": "decode_tokens",
            "component": "token_row",
            "props": {
              "tokens": [
                "Quantum",
                "computing",
                "is",
                "a",
                "type",
                "of"
              ],
              "mode": "decode",
              "label": "DECODE"
            },
            "position": {
              "x": 1440,
              "y": 400
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 11
            },
            "animations": [
              {
                "action": "activate_sequential",
                "at_seconds": 12,
                "duration_seconds": 6,
                "params": {
                  "delay_between": 1
                }
              }
            ]
          },
          {
            "id": "gpu_decode",
            "component": "gpu_gauge",
            "props": {
              "utilization": 5,
              "status": "memory",
              "label": "GPU: Memory-bound"
            },
            "position": {
              "x": 1440,
              "y": 600
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 14
            },
            "animations": [
              {
                "action": "fill",
                "at_seconds": 15,
                "duration_seconds": 1
              }
            ]
          }
        ]
      },
      {
        "id": "scene3_bottleneck",
        "start_seconds": 38.4,
        "end_seconds": 58.8,
        "voiceover": "During decode, something surprising happens. The GPU sits mostly idle, waiting for data. Why? Because we're not limited by compute power. We're limited by memory bandwidth. The model weights are massive - billions of parameters. Moving them from memory to GPU takes time. And we do this for every single token.",
        "audio_file": "scene3_bottleneck.mp3",
        "elements": [
          {
            "id": "bottleneck_title",
            "component": "title_card",
            "props": {
              "title": "The Decode Bottleneck",
              "subtitle": "Memory, not Compute"
            },
            "position": {
              "x": "center",
              "y": 200
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5
            },
            "exit": {
              "type": "fade",
              "duration_seconds": 0.3,
              "delay_seconds": 3
            }
          },
          {
            "id": "gpu_idle",
            "component": "gpu_gauge",
            "props": {
              "utilization": 5,
              "status": "memory",
              "label": "GPU Utilization"
            },
            "position": {
              "x": "center",
              "y": 450
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 2
            },
            "animations": [
              {
                "action": "fill",
                "at_seconds": 3,
                "duration_seconds": 1.5
              },
              {
                "action": "show_status",
                "at_seconds": 5,
                "duration_seconds": 0.3
              }
            ]
          },
          {
            "id": "memory_label",
            "component": "text_reveal",
            "props": {
              "text": "Memory Bandwidth Limited",
              "fontSize": 36,
              "color": "#ff6b35"
            },
            "position": {
              "x": "center",
              "y": 600
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 8
            }
          },
          {
            "id": "params_text",
            "component": "text_reveal",
            "props": {
              "text": "Billions of parameters to load",
              "fontSize": 32
            },
            "position": {
              "x": "center",
              "y": 700
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 12
            }
          },
          {
            "id": "every_token",
            "component": "text_reveal",
            "props": {
              "text": "...for every single token",
              "fontSize": 32,
              "color": "#ff4757"
            },
            "position": {
              "x": "center",
              "y": 780
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 16
            }
          }
        ]
      },
      {
        "id": "scene4_attention",
        "start_seconds": 58.8,
        "end_seconds": 80.0,
        "voiceover": "To understand the solution, we need to understand attention. For each token, we compute three vectors: Query, Key, and Value. The Query asks: what am I looking for? Keys answer: what information do I have? Values hold the actual content. Attention scores tell us which past tokens matter most for the current prediction.",
        "audio_file": "scene4_attention.mp3",
        "elements": [
          {
            "id": "attention_title",
            "component": "title_card",
            "props": {
              "title": "Understanding Attention",
              "subtitle": "Query, Key, Value"
            },
            "position": {
              "x": "center",
              "y": 200
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5
            },
            "exit": {
              "type": "fade",
              "duration_seconds": 0.3,
              "delay_seconds": 3
            }
          },
          {
            "id": "query_text",
            "component": "text_reveal",
            "props": {
              "text": "Query (Q): What am I looking for?",
              "fontSize": 36,
              "color": "#00d9ff"
            },
            "position": {
              "x": "center",
              "y": 400
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 5
            }
          },
          {
            "id": "key_text",
            "component": "text_reveal",
            "props": {
              "text": "Key (K): What information do I have?",
              "fontSize": 36,
              "color": "#ff6b35"
            },
            "position": {
              "x": "center",
              "y": 500
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 8
            }
          },
          {
            "id": "value_text",
            "component": "text_reveal",
            "props": {
              "text": "Value (V): The actual content",
              "fontSize": 36,
              "color": "#00ff88"
            },
            "position": {
              "x": "center",
              "y": 600
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 11
            }
          },
          {
            "id": "attention_formula",
            "component": "text_reveal",
            "props": {
              "text": "Attention = softmax(Q \u00b7 K^T) \u00b7 V",
              "fontSize": 42,
              "color": "#ffffff"
            },
            "position": {
              "x": "center",
              "y": 750
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 16
            }
          }
        ]
      },
      {
        "id": "scene5_redundancy",
        "start_seconds": 80.0,
        "end_seconds": 102.0,
        "voiceover": "Here's the problem with naive decoding. For each new token, we recompute Keys and Values for ALL previous tokens. Token one? Compute once. Token two? Compute everything twice. Token ten? Ten times the work. Token one hundred? You see the pattern. This is O of n squared complexity. Most of this computation is completely redundant.",
        "audio_file": "scene5_redundancy.mp3",
        "elements": [
          {
            "id": "redundancy_title",
            "component": "title_card",
            "props": {
              "title": "The Redundancy Problem",
              "subtitle": "O(n\u00b2) Complexity"
            },
            "position": {
              "x": "center",
              "y": 200
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5
            },
            "exit": {
              "type": "fade",
              "duration_seconds": 0.3,
              "delay_seconds": 3
            }
          },
          {
            "id": "token1",
            "component": "text_reveal",
            "props": {
              "text": "Token 1: Compute 1x",
              "fontSize": 32
            },
            "position": {
              "x": "center",
              "y": 380
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.3,
              "delay_seconds": 5
            }
          },
          {
            "id": "token2",
            "component": "text_reveal",
            "props": {
              "text": "Token 2: Compute 2x",
              "fontSize": 32
            },
            "position": {
              "x": "center",
              "y": 450
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.3,
              "delay_seconds": 7
            }
          },
          {
            "id": "token10",
            "component": "text_reveal",
            "props": {
              "text": "Token 10: Compute 10x",
              "fontSize": 32,
              "color": "#ff6b35"
            },
            "position": {
              "x": "center",
              "y": 520
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.3,
              "delay_seconds": 9
            }
          },
          {
            "id": "token100",
            "component": "text_reveal",
            "props": {
              "text": "Token 100: Compute 100x",
              "fontSize": 32,
              "color": "#ff4757"
            },
            "position": {
              "x": "center",
              "y": 590
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.3,
              "delay_seconds": 11
            }
          },
          {
            "id": "complexity",
            "component": "text_reveal",
            "props": {
              "text": "O(n\u00b2) - Quadratic Complexity",
              "fontSize": 48,
              "color": "#ff4757"
            },
            "position": {
              "x": "center",
              "y": 720
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 15
            }
          },
          {
            "id": "redundant",
            "component": "text_reveal",
            "props": {
              "text": "Most computation is redundant!",
              "fontSize": 36
            },
            "position": {
              "x": "center",
              "y": 820
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 18
            }
          }
        ]
      },
      {
        "id": "scene6_kvcache",
        "start_seconds": 102.0,
        "end_seconds": 119.6,
        "voiceover": "The solution is elegant: the KV Cache. Compute each Key and Value exactly once, then store them. When generating the next token, just look up what you've already computed. No redundant calculations. No wasted work. We trade memory for speed. Compute once. Remember forever.",
        "audio_file": "scene6_kvcache.mp3",
        "elements": [
          {
            "id": "kvcache_title",
            "component": "title_card",
            "props": {
              "title": "The KV Cache",
              "subtitle": "The Solution"
            },
            "position": {
              "x": "center",
              "y": 200
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5
            },
            "exit": {
              "type": "fade",
              "duration_seconds": 0.3,
              "delay_seconds": 2.5
            }
          },
          {
            "id": "compute_once",
            "component": "text_reveal",
            "props": {
              "text": "Compute K, V once",
              "fontSize": 40,
              "color": "#00d9ff"
            },
            "position": {
              "x": "center",
              "y": 400
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 3
            }
          },
          {
            "id": "store_them",
            "component": "text_reveal",
            "props": {
              "text": "Store in cache",
              "fontSize": 40,
              "color": "#ff6b35"
            },
            "position": {
              "x": "center",
              "y": 480
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 5
            }
          },
          {
            "id": "lookup",
            "component": "text_reveal",
            "props": {
              "text": "Look up when needed",
              "fontSize": 40,
              "color": "#00ff88"
            },
            "position": {
              "x": "center",
              "y": 560
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 7
            }
          },
          {
            "id": "tradeoff",
            "component": "text_reveal",
            "props": {
              "text": "Trade memory for speed",
              "fontSize": 48,
              "color": "#a855f7"
            },
            "position": {
              "x": "center",
              "y": 700
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 11
            }
          },
          {
            "id": "motto",
            "component": "text_reveal",
            "props": {
              "text": "Compute once. Remember forever.",
              "fontSize": 42
            },
            "position": {
              "x": "center",
              "y": 800
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 14
            }
          }
        ]
      },
      {
        "id": "scene7_mechanics",
        "start_seconds": 119.6,
        "end_seconds": 138.8,
        "voiceover": "Here's how it works in practice. The new token's Query looks up against the cached Keys. This gives us attention weights. Those weights select from cached Values. The result? Same output, fraction of the compute. Each new token only needs one new Key-Value pair added to the cache.",
        "audio_file": "scene7_mechanics.mp3",
        "elements": [
          {
            "id": "mechanics_title",
            "component": "title_card",
            "props": {
              "title": "How It Works",
              "subtitle": "KV Cache Mechanics"
            },
            "position": {
              "x": "center",
              "y": 200
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5
            },
            "exit": {
              "type": "fade",
              "duration_seconds": 0.3,
              "delay_seconds": 2.5
            }
          },
          {
            "id": "step1",
            "component": "text_reveal",
            "props": {
              "text": "1. New token's Q looks up cached K",
              "fontSize": 32
            },
            "position": {
              "x": "center",
              "y": 380
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 3
            }
          },
          {
            "id": "step2",
            "component": "text_reveal",
            "props": {
              "text": "2. Compute attention weights",
              "fontSize": 32
            },
            "position": {
              "x": "center",
              "y": 460
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 6
            }
          },
          {
            "id": "step3",
            "component": "text_reveal",
            "props": {
              "text": "3. Select from cached V",
              "fontSize": 32
            },
            "position": {
              "x": "center",
              "y": 540
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 8
            }
          },
          {
            "id": "result",
            "component": "text_reveal",
            "props": {
              "text": "Same output, fraction of compute!",
              "fontSize": 40,
              "color": "#00ff88"
            },
            "position": {
              "x": "center",
              "y": 660
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 11
            }
          },
          {
            "id": "one_pair",
            "component": "text_reveal",
            "props": {
              "text": "Only 1 new K-V pair per token",
              "fontSize": 36,
              "color": "#00d9ff"
            },
            "position": {
              "x": "center",
              "y": 780
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 15
            }
          }
        ]
      },
      {
        "id": "scene8_impact",
        "start_seconds": 138.8,
        "end_seconds": 165.0,
        "voiceover": "The impact is massive. Eighty-seven times faster inference. The tradeoff? Memory. A seventy billion parameter model needs about thirty-two gigabytes just for the cache. But it's worth it. Every major LLM uses this technique. GPT-4, Claude, Gemini, LLaMA. KV caching is the foundation of fast LLM inference. Trade memory for speed. Never recompute what you can remember.",
        "audio_file": "scene8_impact.mp3",
        "elements": [
          {
            "id": "impact_title",
            "component": "title_card",
            "props": {
              "title": "The Impact",
              "subtitle": "87x Faster"
            },
            "position": {
              "x": "center",
              "y": 200
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5
            },
            "exit": {
              "type": "fade",
              "duration_seconds": 0.3,
              "delay_seconds": 3
            }
          },
          {
            "id": "speedup_big",
            "component": "text_reveal",
            "props": {
              "text": "87x Faster Inference",
              "fontSize": 64,
              "color": "#00ff88"
            },
            "position": {
              "x": "center",
              "y": 380
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 2
            }
          },
          {
            "id": "memory_cost",
            "component": "text_reveal",
            "props": {
              "text": "70B model = ~32GB cache",
              "fontSize": 36,
              "color": "#ff6b35"
            },
            "position": {
              "x": "center",
              "y": 500
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 6
            }
          },
          {
            "id": "models",
            "component": "text_reveal",
            "props": {
              "text": "GPT-4 | Claude | Gemini | LLaMA",
              "fontSize": 40
            },
            "position": {
              "x": "center",
              "y": 620
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 12
            }
          },
          {
            "id": "foundation",
            "component": "text_reveal",
            "props": {
              "text": "KV Caching: Foundation of Fast LLM Inference",
              "fontSize": 36,
              "color": "#00d9ff"
            },
            "position": {
              "x": "center",
              "y": 740
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 17
            }
          },
          {
            "id": "final_motto",
            "component": "text_reveal",
            "props": {
              "text": "Never recompute what you can remember.",
              "fontSize": 42
            },
            "position": {
              "x": "center",
              "y": 860
            },
            "enter": {
              "type": "fade",
              "duration_seconds": 0.5,
              "delay_seconds": 22
            }
          }
        ]
      }
    ]
  },
  "voiceover": {
    "scenes": [
      {
        "scene_id": "scene1_hook",
        "audio_path": "/Users/prajwal/Desktop/Learning/video_explainer/projects/llm-inference/voiceover/scene1_hook.mp3",
        "duration_seconds": 17.2,
        "word_timestamps": [
          {
            "word": "Every",
            "start_seconds": 0.0,
            "end_seconds": 0.36666666666666664
          },
          {
            "word": "time",
            "start_seconds": 0.41666666666666663,
            "end_seconds": 0.7499999999999999
          },
          {
            "word": "you",
            "start_seconds": 0.7999999999999998,
            "end_seconds": 1.0999999999999999
          },
          {
            "word": "chat",
            "start_seconds": 1.15,
            "end_seconds": 1.4833333333333332
          },
          {
            "word": "with",
            "start_seconds": 1.5333333333333332,
            "end_seconds": 1.8666666666666665
          },
          {
            "word": "an",
            "start_seconds": 1.9166666666666665,
            "end_seconds": 2.183333333333333
          },
          {
            "word": "AI",
            "start_seconds": 2.233333333333333,
            "end_seconds": 2.4999999999999996
          },
          {
            "word": "something",
            "start_seconds": 2.5499999999999994,
            "end_seconds": 3.0499999999999994
          },
          {
            "word": "remarkable",
            "start_seconds": 3.099999999999999,
            "end_seconds": 3.6333333333333324
          },
          {
            "word": "happens",
            "start_seconds": 3.6833333333333327,
            "end_seconds": 4.116666666666666
          },
          {
            "word": "A",
            "start_seconds": 4.166666666666666,
            "end_seconds": 4.3999999999999995
          },
          {
            "word": "neural",
            "start_seconds": 4.449999999999999,
            "end_seconds": 4.85
          },
          {
            "word": "network",
            "start_seconds": 4.8999999999999995,
            "end_seconds": 5.333333333333333
          },
          {
            "word": "generates",
            "start_seconds": 5.383333333333333,
            "end_seconds": 5.883333333333333
          },
          {
            "word": "your",
            "start_seconds": 5.933333333333333,
            "end_seconds": 6.266666666666666
          },
          {
            "word": "response",
            "start_seconds": 6.3166666666666655,
            "end_seconds": 6.783333333333332
          },
          {
            "word": "one",
            "start_seconds": 6.833333333333332,
            "end_seconds": 7.133333333333332
          },
          {
            "word": "word",
            "start_seconds": 7.183333333333332,
            "end_seconds": 7.516666666666665
          },
          {
            "word": "at",
            "start_seconds": 7.566666666666665,
            "end_seconds": 7.833333333333331
          },
          {
            "word": "a",
            "start_seconds": 7.883333333333331,
            "end_seconds": 8.116666666666664
          },
          {
            "word": "time",
            "start_seconds": 8.166666666666664,
            "end_seconds": 8.499999999999998
          },
          {
            "word": "The",
            "start_seconds": 8.549999999999997,
            "end_seconds": 8.849999999999998
          },
          {
            "word": "naive",
            "start_seconds": 8.899999999999997,
            "end_seconds": 9.266666666666664
          },
          {
            "word": "approach",
            "start_seconds": 9.316666666666663,
            "end_seconds": 9.78333333333333
          },
          {
            "word": "Forty",
            "start_seconds": 9.833333333333329,
            "end_seconds": 10.199999999999996
          },
          {
            "word": "tokens",
            "start_seconds": 10.249999999999995,
            "end_seconds": 10.649999999999995
          },
          {
            "word": "per",
            "start_seconds": 10.699999999999994,
            "end_seconds": 10.999999999999995
          },
          {
            "word": "second",
            "start_seconds": 11.049999999999994,
            "end_seconds": 11.449999999999994
          },
          {
            "word": "The",
            "start_seconds": 11.499999999999993,
            "end_seconds": 11.799999999999994
          },
          {
            "word": "best",
            "start_seconds": 11.849999999999993,
            "end_seconds": 12.183333333333326
          },
          {
            "word": "systems",
            "start_seconds": 12.233333333333325,
            "end_seconds": 12.666666666666659
          },
          {
            "word": "Over",
            "start_seconds": 12.716666666666658,
            "end_seconds": 13.049999999999992
          },
          {
            "word": "three",
            "start_seconds": 13.09999999999999,
            "end_seconds": 13.466666666666658
          },
          {
            "word": "thousand",
            "start_seconds": 13.516666666666657,
            "end_seconds": 13.983333333333324
          },
          {
            "word": "That's",
            "start_seconds": 14.033333333333324,
            "end_seconds": 14.433333333333325
          },
          {
            "word": "eighty-seven",
            "start_seconds": 14.483333333333324,
            "end_seconds": 15.083333333333323
          },
          {
            "word": "times",
            "start_seconds": 15.133333333333324,
            "end_seconds": 15.499999999999991
          },
          {
            "word": "faster",
            "start_seconds": 15.54999999999999,
            "end_seconds": 15.94999999999999
          },
          {
            "word": "Here's",
            "start_seconds": 15.99999999999999,
            "end_seconds": 16.399999999999988
          },
          {
            "word": "how",
            "start_seconds": 16.44999999999999,
            "end_seconds": 16.74999999999999
          },
          {
            "word": "they",
            "start_seconds": 16.79999999999999,
            "end_seconds": 17.133333333333322
          },
          {
            "word": "do",
            "start_seconds": 17.183333333333323,
            "end_seconds": 17.44999999999999
          },
          {
            "word": "it",
            "start_seconds": 17.49999999999999,
            "end_seconds": 17.766666666666655
          }
        ]
      },
      {
        "scene_id": "scene2_phases",
        "audio_path": "/Users/prajwal/Desktop/Learning/video_explainer/projects/llm-inference/voiceover/scene2_phases.mp3",
        "duration_seconds": 21.2,
        "word_timestamps": [
          {
            "word": "LLM",
            "start_seconds": 0.0,
            "end_seconds": 0.3
          },
          {
            "word": "inference",
            "start_seconds": 0.35,
            "end_seconds": 0.8499999999999999
          },
          {
            "word": "has",
            "start_seconds": 0.8999999999999999,
            "end_seconds": 1.2
          },
          {
            "word": "two",
            "start_seconds": 1.25,
            "end_seconds": 1.55
          },
          {
            "word": "distinct",
            "start_seconds": 1.6,
            "end_seconds": 2.0666666666666664
          },
          {
            "word": "phases",
            "start_seconds": 2.1166666666666667,
            "end_seconds": 2.5166666666666666
          },
          {
            "word": "First",
            "start_seconds": 2.5666666666666664,
            "end_seconds": 2.933333333333333
          },
          {
            "word": "the",
            "start_seconds": 2.983333333333333,
            "end_seconds": 3.2833333333333328
          },
          {
            "word": "prefill",
            "start_seconds": 3.333333333333333,
            "end_seconds": 3.7666666666666666
          },
          {
            "word": "phase",
            "start_seconds": 3.8166666666666664,
            "end_seconds": 4.183333333333333
          },
          {
            "word": "processes",
            "start_seconds": 4.233333333333333,
            "end_seconds": 4.733333333333333
          },
          {
            "word": "your",
            "start_seconds": 4.783333333333333,
            "end_seconds": 5.116666666666666
          },
          {
            "word": "entire",
            "start_seconds": 5.166666666666666,
            "end_seconds": 5.566666666666666
          },
          {
            "word": "prompt",
            "start_seconds": 5.616666666666666,
            "end_seconds": 6.016666666666667
          },
          {
            "word": "in",
            "start_seconds": 6.066666666666666,
            "end_seconds": 6.333333333333333
          },
          {
            "word": "parallel",
            "start_seconds": 6.383333333333333,
            "end_seconds": 6.85
          },
          {
            "word": "The",
            "start_seconds": 6.8999999999999995,
            "end_seconds": 7.199999999999999
          },
          {
            "word": "GPU",
            "start_seconds": 7.249999999999999,
            "end_seconds": 7.549999999999999
          },
          {
            "word": "loves",
            "start_seconds": 7.599999999999999,
            "end_seconds": 7.966666666666665
          },
          {
            "word": "this",
            "start_seconds": 8.016666666666666,
            "end_seconds": 8.35
          },
          {
            "word": "-",
            "start_seconds": 8.399999999999999,
            "end_seconds": 8.633333333333331
          },
          {
            "word": "it",
            "start_seconds": 8.683333333333332,
            "end_seconds": 8.95
          },
          {
            "word": "can",
            "start_seconds": 8.999999999999998,
            "end_seconds": 9.299999999999999
          },
          {
            "word": "crunch",
            "start_seconds": 9.349999999999998,
            "end_seconds": 9.749999999999998
          },
          {
            "word": "all",
            "start_seconds": 9.799999999999997,
            "end_seconds": 10.099999999999998
          },
          {
            "word": "tokens",
            "start_seconds": 10.149999999999997,
            "end_seconds": 10.549999999999997
          },
          {
            "word": "at",
            "start_seconds": 10.599999999999996,
            "end_seconds": 10.866666666666664
          },
          {
            "word": "once",
            "start_seconds": 10.916666666666663,
            "end_seconds": 11.249999999999996
          },
          {
            "word": "Then",
            "start_seconds": 11.299999999999995,
            "end_seconds": 11.63333333333333
          },
          {
            "word": "comes",
            "start_seconds": 11.683333333333328,
            "end_seconds": 12.049999999999995
          },
          {
            "word": "the",
            "start_seconds": 12.099999999999994,
            "end_seconds": 12.399999999999995
          },
          {
            "word": "decode",
            "start_seconds": 12.449999999999994,
            "end_seconds": 12.849999999999994
          },
          {
            "word": "phase",
            "start_seconds": 12.899999999999993,
            "end_seconds": 13.26666666666666
          },
          {
            "word": "generating",
            "start_seconds": 13.31666666666666,
            "end_seconds": 13.849999999999993
          },
          {
            "word": "one",
            "start_seconds": 13.899999999999993,
            "end_seconds": 14.199999999999994
          },
          {
            "word": "token",
            "start_seconds": 14.249999999999993,
            "end_seconds": 14.61666666666666
          },
          {
            "word": "at",
            "start_seconds": 14.666666666666659,
            "end_seconds": 14.933333333333326
          },
          {
            "word": "a",
            "start_seconds": 14.983333333333325,
            "end_seconds": 15.216666666666658
          },
          {
            "word": "time",
            "start_seconds": 15.266666666666659,
            "end_seconds": 15.599999999999993
          },
          {
            "word": "Each",
            "start_seconds": 15.649999999999991,
            "end_seconds": 15.983333333333325
          },
          {
            "word": "new",
            "start_seconds": 16.033333333333324,
            "end_seconds": 16.333333333333325
          },
          {
            "word": "token",
            "start_seconds": 16.383333333333326,
            "end_seconds": 16.749999999999993
          },
          {
            "word": "depends",
            "start_seconds": 16.799999999999994,
            "end_seconds": 17.233333333333327
          },
          {
            "word": "on",
            "start_seconds": 17.283333333333328,
            "end_seconds": 17.549999999999994
          },
          {
            "word": "the",
            "start_seconds": 17.599999999999994,
            "end_seconds": 17.899999999999995
          },
          {
            "word": "previous",
            "start_seconds": 17.949999999999996,
            "end_seconds": 18.41666666666666
          },
          {
            "word": "one",
            "start_seconds": 18.46666666666666,
            "end_seconds": 18.766666666666662
          },
          {
            "word": "This",
            "start_seconds": 18.816666666666663,
            "end_seconds": 19.149999999999995
          },
          {
            "word": "is",
            "start_seconds": 19.199999999999996,
            "end_seconds": 19.46666666666666
          },
          {
            "word": "where",
            "start_seconds": 19.516666666666662,
            "end_seconds": 19.88333333333333
          },
          {
            "word": "the",
            "start_seconds": 19.93333333333333,
            "end_seconds": 20.23333333333333
          },
          {
            "word": "bottleneck",
            "start_seconds": 20.28333333333333,
            "end_seconds": 20.816666666666666
          },
          {
            "word": "hides",
            "start_seconds": 20.866666666666664,
            "end_seconds": 21.23333333333333
          }
        ]
      },
      {
        "scene_id": "scene3_bottleneck",
        "audio_path": "/Users/prajwal/Desktop/Learning/video_explainer/projects/llm-inference/voiceover/scene3_bottleneck.mp3",
        "duration_seconds": 20.400000000000002,
        "word_timestamps": [
          {
            "word": "During",
            "start_seconds": 0.0,
            "end_seconds": 0.4
          },
          {
            "word": "decode",
            "start_seconds": 0.45,
            "end_seconds": 0.8500000000000001
          },
          {
            "word": "something",
            "start_seconds": 0.9,
            "end_seconds": 1.4
          },
          {
            "word": "surprising",
            "start_seconds": 1.4500000000000002,
            "end_seconds": 1.9833333333333336
          },
          {
            "word": "happens",
            "start_seconds": 2.0333333333333337,
            "end_seconds": 2.4666666666666672
          },
          {
            "word": "The",
            "start_seconds": 2.516666666666667,
            "end_seconds": 2.8166666666666673
          },
          {
            "word": "GPU",
            "start_seconds": 2.866666666666667,
            "end_seconds": 3.166666666666667
          },
          {
            "word": "sits",
            "start_seconds": 3.2166666666666672,
            "end_seconds": 3.5500000000000007
          },
          {
            "word": "mostly",
            "start_seconds": 3.6000000000000005,
            "end_seconds": 4.000000000000001
          },
          {
            "word": "idle",
            "start_seconds": 4.050000000000001,
            "end_seconds": 4.383333333333334
          },
          {
            "word": "waiting",
            "start_seconds": 4.433333333333334,
            "end_seconds": 4.866666666666667
          },
          {
            "word": "for",
            "start_seconds": 4.916666666666667,
            "end_seconds": 5.216666666666667
          },
          {
            "word": "data",
            "start_seconds": 5.266666666666667,
            "end_seconds": 5.6
          },
          {
            "word": "Why",
            "start_seconds": 5.65,
            "end_seconds": 5.95
          },
          {
            "word": "Because",
            "start_seconds": 6.0,
            "end_seconds": 6.433333333333334
          },
          {
            "word": "we're",
            "start_seconds": 6.483333333333333,
            "end_seconds": 6.85
          },
          {
            "word": "not",
            "start_seconds": 6.9,
            "end_seconds": 7.2
          },
          {
            "word": "limited",
            "start_seconds": 7.25,
            "end_seconds": 7.683333333333334
          },
          {
            "word": "by",
            "start_seconds": 7.733333333333333,
            "end_seconds": 8.0
          },
          {
            "word": "compute",
            "start_seconds": 8.05,
            "end_seconds": 8.483333333333334
          },
          {
            "word": "power",
            "start_seconds": 8.533333333333335,
            "end_seconds": 8.900000000000002
          },
          {
            "word": "We're",
            "start_seconds": 8.950000000000001,
            "end_seconds": 9.316666666666668
          },
          {
            "word": "limited",
            "start_seconds": 9.366666666666667,
            "end_seconds": 9.8
          },
          {
            "word": "by",
            "start_seconds": 9.850000000000001,
            "end_seconds": 10.116666666666669
          },
          {
            "word": "memory",
            "start_seconds": 10.166666666666668,
            "end_seconds": 10.566666666666668
          },
          {
            "word": "bandwidth",
            "start_seconds": 10.616666666666667,
            "end_seconds": 11.116666666666667
          },
          {
            "word": "The",
            "start_seconds": 11.166666666666668,
            "end_seconds": 11.466666666666669
          },
          {
            "word": "model",
            "start_seconds": 11.516666666666667,
            "end_seconds": 11.883333333333335
          },
          {
            "word": "weights",
            "start_seconds": 11.933333333333334,
            "end_seconds": 12.366666666666667
          },
          {
            "word": "are",
            "start_seconds": 12.416666666666668,
            "end_seconds": 12.716666666666669
          },
          {
            "word": "massive",
            "start_seconds": 12.766666666666667,
            "end_seconds": 13.200000000000001
          },
          {
            "word": "-",
            "start_seconds": 13.25,
            "end_seconds": 13.483333333333333
          },
          {
            "word": "billions",
            "start_seconds": 13.533333333333333,
            "end_seconds": 14.0
          },
          {
            "word": "of",
            "start_seconds": 14.05,
            "end_seconds": 14.316666666666668
          },
          {
            "word": "parameters",
            "start_seconds": 14.366666666666667,
            "end_seconds": 14.9
          },
          {
            "word": "Moving",
            "start_seconds": 14.950000000000001,
            "end_seconds": 15.350000000000001
          },
          {
            "word": "them",
            "start_seconds": 15.4,
            "end_seconds": 15.733333333333334
          },
          {
            "word": "from",
            "start_seconds": 15.783333333333333,
            "end_seconds": 16.116666666666667
          },
          {
            "word": "memory",
            "start_seconds": 16.166666666666668,
            "end_seconds": 16.566666666666666
          },
          {
            "word": "to",
            "start_seconds": 16.616666666666667,
            "end_seconds": 16.883333333333333
          },
          {
            "word": "GPU",
            "start_seconds": 16.933333333333334,
            "end_seconds": 17.233333333333334
          },
          {
            "word": "takes",
            "start_seconds": 17.283333333333335,
            "end_seconds": 17.650000000000002
          },
          {
            "word": "time",
            "start_seconds": 17.700000000000003,
            "end_seconds": 18.033333333333335
          },
          {
            "word": "And",
            "start_seconds": 18.083333333333336,
            "end_seconds": 18.383333333333336
          },
          {
            "word": "we",
            "start_seconds": 18.433333333333337,
            "end_seconds": 18.700000000000003
          },
          {
            "word": "do",
            "start_seconds": 18.750000000000004,
            "end_seconds": 19.01666666666667
          },
          {
            "word": "this",
            "start_seconds": 19.06666666666667,
            "end_seconds": 19.400000000000002
          },
          {
            "word": "for",
            "start_seconds": 19.450000000000003,
            "end_seconds": 19.750000000000004
          },
          {
            "word": "every",
            "start_seconds": 19.800000000000004,
            "end_seconds": 20.16666666666667
          },
          {
            "word": "single",
            "start_seconds": 20.216666666666672,
            "end_seconds": 20.61666666666667
          },
          {
            "word": "token",
            "start_seconds": 20.66666666666667,
            "end_seconds": 21.03333333333334
          }
        ]
      },
      {
        "scene_id": "scene4_attention",
        "audio_path": "/Users/prajwal/Desktop/Learning/video_explainer/projects/llm-inference/voiceover/scene4_attention.mp3",
        "duration_seconds": 21.2,
        "word_timestamps": [
          {
            "word": "To",
            "start_seconds": 0.0,
            "end_seconds": 0.2666666666666666
          },
          {
            "word": "understand",
            "start_seconds": 0.3166666666666666,
            "end_seconds": 0.8499999999999999
          },
          {
            "word": "the",
            "start_seconds": 0.8999999999999999,
            "end_seconds": 1.2
          },
          {
            "word": "solution",
            "start_seconds": 1.25,
            "end_seconds": 1.7166666666666666
          },
          {
            "word": "we",
            "start_seconds": 1.7666666666666666,
            "end_seconds": 2.033333333333333
          },
          {
            "word": "need",
            "start_seconds": 2.083333333333333,
            "end_seconds": 2.416666666666666
          },
          {
            "word": "to",
            "start_seconds": 2.4666666666666663,
            "end_seconds": 2.733333333333333
          },
          {
            "word": "understand",
            "start_seconds": 2.7833333333333328,
            "end_seconds": 3.316666666666666
          },
          {
            "word": "attention",
            "start_seconds": 3.3666666666666663,
            "end_seconds": 3.8666666666666663
          },
          {
            "word": "For",
            "start_seconds": 3.916666666666666,
            "end_seconds": 4.216666666666666
          },
          {
            "word": "each",
            "start_seconds": 4.266666666666666,
            "end_seconds": 4.599999999999999
          },
          {
            "word": "token",
            "start_seconds": 4.649999999999999,
            "end_seconds": 5.016666666666665
          },
          {
            "word": "we",
            "start_seconds": 5.0666666666666655,
            "end_seconds": 5.333333333333332
          },
          {
            "word": "compute",
            "start_seconds": 5.383333333333332,
            "end_seconds": 5.8166666666666655
          },
          {
            "word": "three",
            "start_seconds": 5.866666666666665,
            "end_seconds": 6.233333333333332
          },
          {
            "word": "vectors",
            "start_seconds": 6.283333333333332,
            "end_seconds": 6.716666666666666
          },
          {
            "word": "Query",
            "start_seconds": 6.766666666666666,
            "end_seconds": 7.133333333333332
          },
          {
            "word": "Key",
            "start_seconds": 7.183333333333333,
            "end_seconds": 7.4833333333333325
          },
          {
            "word": "and",
            "start_seconds": 7.533333333333332,
            "end_seconds": 7.833333333333332
          },
          {
            "word": "Value",
            "start_seconds": 7.883333333333332,
            "end_seconds": 8.249999999999998
          },
          {
            "word": "The",
            "start_seconds": 8.299999999999999,
            "end_seconds": 8.6
          },
          {
            "word": "Query",
            "start_seconds": 8.649999999999999,
            "end_seconds": 9.016666666666666
          },
          {
            "word": "asks",
            "start_seconds": 9.066666666666665,
            "end_seconds": 9.399999999999999
          },
          {
            "word": "what",
            "start_seconds": 9.449999999999998,
            "end_seconds": 9.783333333333331
          },
          {
            "word": "am",
            "start_seconds": 9.83333333333333,
            "end_seconds": 10.099999999999998
          },
          {
            "word": "I",
            "start_seconds": 10.149999999999997,
            "end_seconds": 10.38333333333333
          },
          {
            "word": "looking",
            "start_seconds": 10.43333333333333,
            "end_seconds": 10.866666666666664
          },
          {
            "word": "for",
            "start_seconds": 10.916666666666663,
            "end_seconds": 11.216666666666663
          },
          {
            "word": "Keys",
            "start_seconds": 11.266666666666662,
            "end_seconds": 11.599999999999996
          },
          {
            "word": "answer",
            "start_seconds": 11.649999999999995,
            "end_seconds": 12.049999999999995
          },
          {
            "word": "what",
            "start_seconds": 12.099999999999994,
            "end_seconds": 12.433333333333328
          },
          {
            "word": "information",
            "start_seconds": 12.483333333333327,
            "end_seconds": 13.049999999999994
          },
          {
            "word": "do",
            "start_seconds": 13.099999999999994,
            "end_seconds": 13.36666666666666
          },
          {
            "word": "I",
            "start_seconds": 13.41666666666666,
            "end_seconds": 13.649999999999993
          },
          {
            "word": "have",
            "start_seconds": 13.699999999999994,
            "end_seconds": 14.033333333333328
          },
          {
            "word": "Values",
            "start_seconds": 14.083333333333327,
            "end_seconds": 14.483333333333327
          },
          {
            "word": "hold",
            "start_seconds": 14.533333333333326,
            "end_seconds": 14.86666666666666
          },
          {
            "word": "the",
            "start_seconds": 14.916666666666659,
            "end_seconds": 15.21666666666666
          },
          {
            "word": "actual",
            "start_seconds": 15.266666666666659,
            "end_seconds": 15.666666666666659
          },
          {
            "word": "content",
            "start_seconds": 15.716666666666658,
            "end_seconds": 16.14999999999999
          },
          {
            "word": "Attention",
            "start_seconds": 16.199999999999992,
            "end_seconds": 16.699999999999992
          },
          {
            "word": "scores",
            "start_seconds": 16.749999999999993,
            "end_seconds": 17.14999999999999
          },
          {
            "word": "tell",
            "start_seconds": 17.199999999999992,
            "end_seconds": 17.533333333333324
          },
          {
            "word": "us",
            "start_seconds": 17.583333333333325,
            "end_seconds": 17.84999999999999
          },
          {
            "word": "which",
            "start_seconds": 17.89999999999999,
            "end_seconds": 18.26666666666666
          },
          {
            "word": "past",
            "start_seconds": 18.31666666666666,
            "end_seconds": 18.64999999999999
          },
          {
            "word": "tokens",
            "start_seconds": 18.699999999999992,
            "end_seconds": 19.09999999999999
          },
          {
            "word": "matter",
            "start_seconds": 19.14999999999999,
            "end_seconds": 19.54999999999999
          },
          {
            "word": "most",
            "start_seconds": 19.59999999999999,
            "end_seconds": 19.933333333333323
          },
          {
            "word": "for",
            "start_seconds": 19.983333333333324,
            "end_seconds": 20.283333333333324
          },
          {
            "word": "the",
            "start_seconds": 20.333333333333325,
            "end_seconds": 20.633333333333326
          },
          {
            "word": "current",
            "start_seconds": 20.683333333333326,
            "end_seconds": 21.11666666666666
          },
          {
            "word": "prediction",
            "start_seconds": 21.16666666666666,
            "end_seconds": 21.699999999999996
          }
        ]
      },
      {
        "scene_id": "scene5_redundancy",
        "audio_path": "/Users/prajwal/Desktop/Learning/video_explainer/projects/llm-inference/voiceover/scene5_redundancy.mp3",
        "duration_seconds": 22.0,
        "word_timestamps": [
          {
            "word": "Here's",
            "start_seconds": 0.0,
            "end_seconds": 0.4
          },
          {
            "word": "the",
            "start_seconds": 0.45,
            "end_seconds": 0.75
          },
          {
            "word": "problem",
            "start_seconds": 0.8,
            "end_seconds": 1.2333333333333334
          },
          {
            "word": "with",
            "start_seconds": 1.2833333333333334,
            "end_seconds": 1.6166666666666667
          },
          {
            "word": "naive",
            "start_seconds": 1.6666666666666667,
            "end_seconds": 2.033333333333333
          },
          {
            "word": "decoding",
            "start_seconds": 2.0833333333333335,
            "end_seconds": 2.5500000000000003
          },
          {
            "word": "For",
            "start_seconds": 2.6,
            "end_seconds": 2.9000000000000004
          },
          {
            "word": "each",
            "start_seconds": 2.95,
            "end_seconds": 3.2833333333333337
          },
          {
            "word": "new",
            "start_seconds": 3.3333333333333335,
            "end_seconds": 3.6333333333333337
          },
          {
            "word": "token",
            "start_seconds": 3.6833333333333336,
            "end_seconds": 4.050000000000001
          },
          {
            "word": "we",
            "start_seconds": 4.1000000000000005,
            "end_seconds": 4.366666666666667
          },
          {
            "word": "recompute",
            "start_seconds": 4.416666666666667,
            "end_seconds": 4.916666666666667
          },
          {
            "word": "Keys",
            "start_seconds": 4.966666666666667,
            "end_seconds": 5.3
          },
          {
            "word": "and",
            "start_seconds": 5.35,
            "end_seconds": 5.6499999999999995
          },
          {
            "word": "Values",
            "start_seconds": 5.699999999999999,
            "end_seconds": 6.1
          },
          {
            "word": "for",
            "start_seconds": 6.1499999999999995,
            "end_seconds": 6.449999999999999
          },
          {
            "word": "ALL",
            "start_seconds": 6.499999999999999,
            "end_seconds": 6.799999999999999
          },
          {
            "word": "previous",
            "start_seconds": 6.849999999999999,
            "end_seconds": 7.3166666666666655
          },
          {
            "word": "tokens",
            "start_seconds": 7.366666666666665,
            "end_seconds": 7.766666666666666
          },
          {
            "word": "Token",
            "start_seconds": 7.8166666666666655,
            "end_seconds": 8.183333333333332
          },
          {
            "word": "one",
            "start_seconds": 8.233333333333333,
            "end_seconds": 8.533333333333333
          },
          {
            "word": "Compute",
            "start_seconds": 8.583333333333332,
            "end_seconds": 9.016666666666666
          },
          {
            "word": "once",
            "start_seconds": 9.066666666666666,
            "end_seconds": 9.4
          },
          {
            "word": "Token",
            "start_seconds": 9.45,
            "end_seconds": 9.816666666666666
          },
          {
            "word": "two",
            "start_seconds": 9.866666666666665,
            "end_seconds": 10.166666666666666
          },
          {
            "word": "Compute",
            "start_seconds": 10.216666666666665,
            "end_seconds": 10.649999999999999
          },
          {
            "word": "everything",
            "start_seconds": 10.7,
            "end_seconds": 11.233333333333333
          },
          {
            "word": "twice",
            "start_seconds": 11.283333333333333,
            "end_seconds": 11.65
          },
          {
            "word": "Token",
            "start_seconds": 11.7,
            "end_seconds": 12.066666666666666
          },
          {
            "word": "ten",
            "start_seconds": 12.116666666666665,
            "end_seconds": 12.416666666666666
          },
          {
            "word": "Ten",
            "start_seconds": 12.466666666666665,
            "end_seconds": 12.766666666666666
          },
          {
            "word": "times",
            "start_seconds": 12.816666666666665,
            "end_seconds": 13.183333333333332
          },
          {
            "word": "the",
            "start_seconds": 13.23333333333333,
            "end_seconds": 13.533333333333331
          },
          {
            "word": "work",
            "start_seconds": 13.58333333333333,
            "end_seconds": 13.916666666666664
          },
          {
            "word": "Token",
            "start_seconds": 13.966666666666663,
            "end_seconds": 14.33333333333333
          },
          {
            "word": "one",
            "start_seconds": 14.38333333333333,
            "end_seconds": 14.68333333333333
          },
          {
            "word": "hundred",
            "start_seconds": 14.733333333333329,
            "end_seconds": 15.166666666666663
          },
          {
            "word": "You",
            "start_seconds": 15.216666666666661,
            "end_seconds": 15.516666666666662
          },
          {
            "word": "see",
            "start_seconds": 15.566666666666661,
            "end_seconds": 15.866666666666662
          },
          {
            "word": "the",
            "start_seconds": 15.91666666666666,
            "end_seconds": 16.21666666666666
          },
          {
            "word": "pattern",
            "start_seconds": 16.266666666666662,
            "end_seconds": 16.699999999999996
          },
          {
            "word": "This",
            "start_seconds": 16.749999999999996,
            "end_seconds": 17.08333333333333
          },
          {
            "word": "is",
            "start_seconds": 17.13333333333333,
            "end_seconds": 17.399999999999995
          },
          {
            "word": "O",
            "start_seconds": 17.449999999999996,
            "end_seconds": 17.68333333333333
          },
          {
            "word": "of",
            "start_seconds": 17.73333333333333,
            "end_seconds": 17.999999999999996
          },
          {
            "word": "n",
            "start_seconds": 18.049999999999997,
            "end_seconds": 18.28333333333333
          },
          {
            "word": "squared",
            "start_seconds": 18.333333333333332,
            "end_seconds": 18.766666666666666
          },
          {
            "word": "complexity",
            "start_seconds": 18.816666666666666,
            "end_seconds": 19.35
          },
          {
            "word": "Most",
            "start_seconds": 19.4,
            "end_seconds": 19.73333333333333
          },
          {
            "word": "of",
            "start_seconds": 19.78333333333333,
            "end_seconds": 20.049999999999997
          },
          {
            "word": "this",
            "start_seconds": 20.099999999999998,
            "end_seconds": 20.43333333333333
          },
          {
            "word": "computation",
            "start_seconds": 20.48333333333333,
            "end_seconds": 21.049999999999997
          },
          {
            "word": "is",
            "start_seconds": 21.099999999999998,
            "end_seconds": 21.366666666666664
          },
          {
            "word": "completely",
            "start_seconds": 21.416666666666664,
            "end_seconds": 21.95
          },
          {
            "word": "redundant",
            "start_seconds": 21.999999999999996,
            "end_seconds": 22.499999999999996
          }
        ]
      },
      {
        "scene_id": "scene6_kvcache",
        "audio_path": "/Users/prajwal/Desktop/Learning/video_explainer/projects/llm-inference/voiceover/scene6_kvcache.mp3",
        "duration_seconds": 17.6,
        "word_timestamps": [
          {
            "word": "The",
            "start_seconds": 0.0,
            "end_seconds": 0.30000000000000004
          },
          {
            "word": "solution",
            "start_seconds": 0.35000000000000003,
            "end_seconds": 0.8166666666666667
          },
          {
            "word": "is",
            "start_seconds": 0.8666666666666667,
            "end_seconds": 1.1333333333333333
          },
          {
            "word": "elegant",
            "start_seconds": 1.1833333333333333,
            "end_seconds": 1.6166666666666667
          },
          {
            "word": "the",
            "start_seconds": 1.6666666666666667,
            "end_seconds": 1.9666666666666668
          },
          {
            "word": "KV",
            "start_seconds": 2.0166666666666666,
            "end_seconds": 2.283333333333333
          },
          {
            "word": "Cache",
            "start_seconds": 2.333333333333333,
            "end_seconds": 2.6999999999999997
          },
          {
            "word": "Compute",
            "start_seconds": 2.7499999999999996,
            "end_seconds": 3.183333333333333
          },
          {
            "word": "each",
            "start_seconds": 3.233333333333333,
            "end_seconds": 3.5666666666666664
          },
          {
            "word": "Key",
            "start_seconds": 3.6166666666666663,
            "end_seconds": 3.916666666666666
          },
          {
            "word": "and",
            "start_seconds": 3.9666666666666663,
            "end_seconds": 4.266666666666667
          },
          {
            "word": "Value",
            "start_seconds": 4.316666666666666,
            "end_seconds": 4.683333333333334
          },
          {
            "word": "exactly",
            "start_seconds": 4.733333333333333,
            "end_seconds": 5.166666666666667
          },
          {
            "word": "once",
            "start_seconds": 5.216666666666667,
            "end_seconds": 5.55
          },
          {
            "word": "then",
            "start_seconds": 5.6,
            "end_seconds": 5.933333333333333
          },
          {
            "word": "store",
            "start_seconds": 5.9833333333333325,
            "end_seconds": 6.35
          },
          {
            "word": "them",
            "start_seconds": 6.3999999999999995,
            "end_seconds": 6.7333333333333325
          },
          {
            "word": "When",
            "start_seconds": 6.783333333333333,
            "end_seconds": 7.116666666666666
          },
          {
            "word": "generating",
            "start_seconds": 7.166666666666666,
            "end_seconds": 7.699999999999999
          },
          {
            "word": "the",
            "start_seconds": 7.75,
            "end_seconds": 8.05
          },
          {
            "word": "next",
            "start_seconds": 8.1,
            "end_seconds": 8.433333333333334
          },
          {
            "word": "token",
            "start_seconds": 8.483333333333333,
            "end_seconds": 8.85
          },
          {
            "word": "just",
            "start_seconds": 8.899999999999999,
            "end_seconds": 9.233333333333333
          },
          {
            "word": "look",
            "start_seconds": 9.283333333333331,
            "end_seconds": 9.616666666666665
          },
          {
            "word": "up",
            "start_seconds": 9.666666666666664,
            "end_seconds": 9.933333333333332
          },
          {
            "word": "what",
            "start_seconds": 9.98333333333333,
            "end_seconds": 10.316666666666665
          },
          {
            "word": "you've",
            "start_seconds": 10.366666666666664,
            "end_seconds": 10.766666666666664
          },
          {
            "word": "already",
            "start_seconds": 10.816666666666663,
            "end_seconds": 11.249999999999996
          },
          {
            "word": "computed",
            "start_seconds": 11.299999999999997,
            "end_seconds": 11.766666666666664
          },
          {
            "word": "No",
            "start_seconds": 11.816666666666663,
            "end_seconds": 12.08333333333333
          },
          {
            "word": "redundant",
            "start_seconds": 12.13333333333333,
            "end_seconds": 12.63333333333333
          },
          {
            "word": "calculations",
            "start_seconds": 12.68333333333333,
            "end_seconds": 13.28333333333333
          },
          {
            "word": "No",
            "start_seconds": 13.33333333333333,
            "end_seconds": 13.599999999999998
          },
          {
            "word": "wasted",
            "start_seconds": 13.649999999999997,
            "end_seconds": 14.049999999999997
          },
          {
            "word": "work",
            "start_seconds": 14.099999999999996,
            "end_seconds": 14.43333333333333
          },
          {
            "word": "We",
            "start_seconds": 14.483333333333329,
            "end_seconds": 14.749999999999996
          },
          {
            "word": "trade",
            "start_seconds": 14.799999999999995,
            "end_seconds": 15.166666666666663
          },
          {
            "word": "memory",
            "start_seconds": 15.216666666666661,
            "end_seconds": 15.616666666666662
          },
          {
            "word": "for",
            "start_seconds": 15.66666666666666,
            "end_seconds": 15.966666666666661
          },
          {
            "word": "speed",
            "start_seconds": 16.016666666666662,
            "end_seconds": 16.38333333333333
          },
          {
            "word": "Compute",
            "start_seconds": 16.43333333333333,
            "end_seconds": 16.866666666666664
          },
          {
            "word": "once",
            "start_seconds": 16.916666666666664,
            "end_seconds": 17.249999999999996
          },
          {
            "word": "Remember",
            "start_seconds": 17.299999999999997,
            "end_seconds": 17.766666666666662
          },
          {
            "word": "forever",
            "start_seconds": 17.816666666666663,
            "end_seconds": 18.249999999999996
          }
        ]
      },
      {
        "scene_id": "scene7_mechanics",
        "audio_path": "/Users/prajwal/Desktop/Learning/video_explainer/projects/llm-inference/voiceover/scene7_mechanics.mp3",
        "duration_seconds": 19.2,
        "word_timestamps": [
          {
            "word": "Here's",
            "start_seconds": 0.0,
            "end_seconds": 0.39999999999999997
          },
          {
            "word": "how",
            "start_seconds": 0.44999999999999996,
            "end_seconds": 0.75
          },
          {
            "word": "it",
            "start_seconds": 0.7999999999999999,
            "end_seconds": 1.0666666666666664
          },
          {
            "word": "works",
            "start_seconds": 1.1166666666666665,
            "end_seconds": 1.4833333333333332
          },
          {
            "word": "in",
            "start_seconds": 1.5333333333333332,
            "end_seconds": 1.7999999999999998
          },
          {
            "word": "practice",
            "start_seconds": 1.8499999999999999,
            "end_seconds": 2.3166666666666664
          },
          {
            "word": "The",
            "start_seconds": 2.3666666666666663,
            "end_seconds": 2.666666666666666
          },
          {
            "word": "new",
            "start_seconds": 2.7166666666666663,
            "end_seconds": 3.016666666666666
          },
          {
            "word": "token's",
            "start_seconds": 3.0666666666666664,
            "end_seconds": 3.5
          },
          {
            "word": "Query",
            "start_seconds": 3.55,
            "end_seconds": 3.9166666666666665
          },
          {
            "word": "looks",
            "start_seconds": 3.9666666666666663,
            "end_seconds": 4.333333333333333
          },
          {
            "word": "up",
            "start_seconds": 4.383333333333333,
            "end_seconds": 4.6499999999999995
          },
          {
            "word": "against",
            "start_seconds": 4.699999999999999,
            "end_seconds": 5.133333333333333
          },
          {
            "word": "the",
            "start_seconds": 5.183333333333333,
            "end_seconds": 5.4833333333333325
          },
          {
            "word": "cached",
            "start_seconds": 5.533333333333332,
            "end_seconds": 5.933333333333333
          },
          {
            "word": "Keys",
            "start_seconds": 5.9833333333333325,
            "end_seconds": 6.3166666666666655
          },
          {
            "word": "This",
            "start_seconds": 6.366666666666665,
            "end_seconds": 6.699999999999998
          },
          {
            "word": "gives",
            "start_seconds": 6.749999999999998,
            "end_seconds": 7.1166666666666645
          },
          {
            "word": "us",
            "start_seconds": 7.166666666666665,
            "end_seconds": 7.433333333333332
          },
          {
            "word": "attention",
            "start_seconds": 7.483333333333332,
            "end_seconds": 7.983333333333332
          },
          {
            "word": "weights",
            "start_seconds": 8.033333333333331,
            "end_seconds": 8.466666666666665
          },
          {
            "word": "Those",
            "start_seconds": 8.516666666666664,
            "end_seconds": 8.883333333333331
          },
          {
            "word": "weights",
            "start_seconds": 8.93333333333333,
            "end_seconds": 9.366666666666664
          },
          {
            "word": "select",
            "start_seconds": 9.416666666666663,
            "end_seconds": 9.816666666666663
          },
          {
            "word": "from",
            "start_seconds": 9.866666666666662,
            "end_seconds": 10.199999999999996
          },
          {
            "word": "cached",
            "start_seconds": 10.249999999999995,
            "end_seconds": 10.649999999999995
          },
          {
            "word": "Values",
            "start_seconds": 10.699999999999994,
            "end_seconds": 11.099999999999994
          },
          {
            "word": "The",
            "start_seconds": 11.149999999999993,
            "end_seconds": 11.449999999999994
          },
          {
            "word": "result",
            "start_seconds": 11.499999999999993,
            "end_seconds": 11.899999999999993
          },
          {
            "word": "Same",
            "start_seconds": 11.949999999999992,
            "end_seconds": 12.283333333333326
          },
          {
            "word": "output",
            "start_seconds": 12.333333333333325,
            "end_seconds": 12.733333333333325
          },
          {
            "word": "fraction",
            "start_seconds": 12.783333333333324,
            "end_seconds": 13.249999999999991
          },
          {
            "word": "of",
            "start_seconds": 13.29999999999999,
            "end_seconds": 13.566666666666656
          },
          {
            "word": "the",
            "start_seconds": 13.616666666666656,
            "end_seconds": 13.916666666666657
          },
          {
            "word": "compute",
            "start_seconds": 13.966666666666656,
            "end_seconds": 14.39999999999999
          },
          {
            "word": "Each",
            "start_seconds": 14.449999999999989,
            "end_seconds": 14.783333333333323
          },
          {
            "word": "new",
            "start_seconds": 14.833333333333321,
            "end_seconds": 15.133333333333322
          },
          {
            "word": "token",
            "start_seconds": 15.183333333333321,
            "end_seconds": 15.549999999999988
          },
          {
            "word": "only",
            "start_seconds": 15.599999999999987,
            "end_seconds": 15.933333333333321
          },
          {
            "word": "needs",
            "start_seconds": 15.98333333333332,
            "end_seconds": 16.349999999999987
          },
          {
            "word": "one",
            "start_seconds": 16.399999999999988,
            "end_seconds": 16.69999999999999
          },
          {
            "word": "new",
            "start_seconds": 16.74999999999999,
            "end_seconds": 17.04999999999999
          },
          {
            "word": "Key-Value",
            "start_seconds": 17.09999999999999,
            "end_seconds": 17.59999999999999
          },
          {
            "word": "pair",
            "start_seconds": 17.64999999999999,
            "end_seconds": 17.983333333333324
          },
          {
            "word": "added",
            "start_seconds": 18.033333333333324,
            "end_seconds": 18.39999999999999
          },
          {
            "word": "to",
            "start_seconds": 18.449999999999992,
            "end_seconds": 18.716666666666658
          },
          {
            "word": "the",
            "start_seconds": 18.76666666666666,
            "end_seconds": 19.06666666666666
          },
          {
            "word": "cache",
            "start_seconds": 19.11666666666666,
            "end_seconds": 19.483333333333327
          }
        ]
      },
      {
        "scene_id": "scene8_impact",
        "audio_path": "/Users/prajwal/Desktop/Learning/video_explainer/projects/llm-inference/voiceover/scene8_impact.mp3",
        "duration_seconds": 22.8,
        "word_timestamps": [
          {
            "word": "The",
            "start_seconds": 0.0,
            "end_seconds": 0.30000000000000004
          },
          {
            "word": "impact",
            "start_seconds": 0.35000000000000003,
            "end_seconds": 0.75
          },
          {
            "word": "is",
            "start_seconds": 0.8,
            "end_seconds": 1.0666666666666667
          },
          {
            "word": "massive",
            "start_seconds": 1.1166666666666667,
            "end_seconds": 1.55
          },
          {
            "word": "Eighty-seven",
            "start_seconds": 1.6,
            "end_seconds": 2.2
          },
          {
            "word": "times",
            "start_seconds": 2.25,
            "end_seconds": 2.6166666666666667
          },
          {
            "word": "faster",
            "start_seconds": 2.6666666666666665,
            "end_seconds": 3.0666666666666664
          },
          {
            "word": "inference",
            "start_seconds": 3.1166666666666667,
            "end_seconds": 3.6166666666666667
          },
          {
            "word": "The",
            "start_seconds": 3.666666666666667,
            "end_seconds": 3.966666666666667
          },
          {
            "word": "tradeoff",
            "start_seconds": 4.016666666666667,
            "end_seconds": 4.483333333333333
          },
          {
            "word": "Memory",
            "start_seconds": 4.533333333333333,
            "end_seconds": 4.933333333333334
          },
          {
            "word": "A",
            "start_seconds": 4.983333333333333,
            "end_seconds": 5.216666666666667
          },
          {
            "word": "seventy",
            "start_seconds": 5.266666666666667,
            "end_seconds": 5.7
          },
          {
            "word": "billion",
            "start_seconds": 5.75,
            "end_seconds": 6.183333333333334
          },
          {
            "word": "parameter",
            "start_seconds": 6.233333333333333,
            "end_seconds": 6.733333333333333
          },
          {
            "word": "model",
            "start_seconds": 6.783333333333333,
            "end_seconds": 7.15
          },
          {
            "word": "needs",
            "start_seconds": 7.2,
            "end_seconds": 7.566666666666666
          },
          {
            "word": "about",
            "start_seconds": 7.616666666666667,
            "end_seconds": 7.983333333333334
          },
          {
            "word": "thirty-two",
            "start_seconds": 8.033333333333333,
            "end_seconds": 8.566666666666666
          },
          {
            "word": "gigabytes",
            "start_seconds": 8.616666666666667,
            "end_seconds": 9.116666666666667
          },
          {
            "word": "just",
            "start_seconds": 9.166666666666668,
            "end_seconds": 9.500000000000002
          },
          {
            "word": "for",
            "start_seconds": 9.55,
            "end_seconds": 9.850000000000001
          },
          {
            "word": "the",
            "start_seconds": 9.9,
            "end_seconds": 10.200000000000001
          },
          {
            "word": "cache",
            "start_seconds": 10.25,
            "end_seconds": 10.616666666666667
          },
          {
            "word": "But",
            "start_seconds": 10.666666666666666,
            "end_seconds": 10.966666666666667
          },
          {
            "word": "it's",
            "start_seconds": 11.016666666666666,
            "end_seconds": 11.35
          },
          {
            "word": "worth",
            "start_seconds": 11.399999999999999,
            "end_seconds": 11.766666666666666
          },
          {
            "word": "it",
            "start_seconds": 11.816666666666665,
            "end_seconds": 12.083333333333332
          },
          {
            "word": "Every",
            "start_seconds": 12.133333333333331,
            "end_seconds": 12.499999999999998
          },
          {
            "word": "major",
            "start_seconds": 12.549999999999997,
            "end_seconds": 12.916666666666664
          },
          {
            "word": "LLM",
            "start_seconds": 12.966666666666663,
            "end_seconds": 13.266666666666664
          },
          {
            "word": "uses",
            "start_seconds": 13.316666666666663,
            "end_seconds": 13.649999999999997
          },
          {
            "word": "this",
            "start_seconds": 13.699999999999996,
            "end_seconds": 14.03333333333333
          },
          {
            "word": "technique",
            "start_seconds": 14.083333333333329,
            "end_seconds": 14.583333333333329
          },
          {
            "word": "GPT-4",
            "start_seconds": 14.63333333333333,
            "end_seconds": 14.999999999999996
          },
          {
            "word": "Claude",
            "start_seconds": 15.049999999999995,
            "end_seconds": 15.449999999999996
          },
          {
            "word": "Gemini",
            "start_seconds": 15.499999999999995,
            "end_seconds": 15.899999999999995
          },
          {
            "word": "LLaMA",
            "start_seconds": 15.949999999999994,
            "end_seconds": 16.31666666666666
          },
          {
            "word": "KV",
            "start_seconds": 16.36666666666666,
            "end_seconds": 16.633333333333326
          },
          {
            "word": "caching",
            "start_seconds": 16.683333333333326,
            "end_seconds": 17.11666666666666
          },
          {
            "word": "is",
            "start_seconds": 17.16666666666666,
            "end_seconds": 17.433333333333326
          },
          {
            "word": "the",
            "start_seconds": 17.483333333333327,
            "end_seconds": 17.783333333333328
          },
          {
            "word": "foundation",
            "start_seconds": 17.83333333333333,
            "end_seconds": 18.366666666666664
          },
          {
            "word": "of",
            "start_seconds": 18.41666666666666,
            "end_seconds": 18.683333333333326
          },
          {
            "word": "fast",
            "start_seconds": 18.733333333333327,
            "end_seconds": 19.06666666666666
          },
          {
            "word": "LLM",
            "start_seconds": 19.11666666666666,
            "end_seconds": 19.41666666666666
          },
          {
            "word": "inference",
            "start_seconds": 19.46666666666666,
            "end_seconds": 19.96666666666666
          },
          {
            "word": "Trade",
            "start_seconds": 20.016666666666662,
            "end_seconds": 20.38333333333333
          },
          {
            "word": "memory",
            "start_seconds": 20.43333333333333,
            "end_seconds": 20.83333333333333
          },
          {
            "word": "for",
            "start_seconds": 20.88333333333333,
            "end_seconds": 21.18333333333333
          },
          {
            "word": "speed",
            "start_seconds": 21.23333333333333,
            "end_seconds": 21.599999999999998
          },
          {
            "word": "Never",
            "start_seconds": 21.65,
            "end_seconds": 22.016666666666666
          },
          {
            "word": "recompute",
            "start_seconds": 22.066666666666666,
            "end_seconds": 22.566666666666666
          },
          {
            "word": "what",
            "start_seconds": 22.616666666666667,
            "end_seconds": 22.95
          },
          {
            "word": "you",
            "start_seconds": 23.0,
            "end_seconds": 23.3
          },
          {
            "word": "can",
            "start_seconds": 23.35,
            "end_seconds": 23.650000000000002
          },
          {
            "word": "remember",
            "start_seconds": 23.700000000000003,
            "end_seconds": 24.166666666666668
          }
        ]
      }
    ],
    "total_duration_seconds": 161.6,
    "output_dir": "/Users/prajwal/Desktop/Learning/video_explainer/projects/llm-inference/voiceover"
  }
}